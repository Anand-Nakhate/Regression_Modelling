import logging
from typing import List, Dict
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


class DecileForwardAnalysis:
    """
    Assign rolling deciles on X, compute forward returns on Y, 
    and aggregate metrics by decile.
    """
    def __init__(self, df: pd.DataFrame, x_col: str, y_col: str, window: int = 252):
        """
        Parameters
        ----------
        df : pd.DataFrame
            Must be indexed by date, with columns for X and Y.
        x_col : str
            Predictor column name (e.g. 'convenience_yield').
        y_col : str
            Target column name (e.g. 'term_premium').
        window : int
            Rolling window size in trading days (default 252 ≈ 1 year).
        """
        self.df = df.copy()
        self.x_col = x_col
        self.y_col = y_col
        self.window = window

    def assign_deciles(self) -> None:
        """Compute rolling 10-decile labels of X."""
        logger.info("Assigning rolling deciles on %s over window %d", self.x_col, self.window)
        # rank each window, then map to deciles 1–10
        self.df['decile'] = (
            self.df[self.x_col]
            .rolling(self.window, min_periods=self.window)
            .apply(lambda arr: pd.qcut(arr, 10, labels=False, duplicates='drop')[-1] + 1)
        )

    def compute_forward_returns(self, horizons: List[int]) -> None:
        """
        For each horizon, compute forward change/return for Y.
        
        Adds columns: fwd_{h}d for each h in horizons.
        """
        logger.info("Computing forward returns for horizons %s", horizons)
        for h in horizons:
            col = f"fwd_{h}d"
            self.df[col] = self.df[self.y_col].pct_change(periods=h).shift(-h)
    
    def aggregate_metrics(self, horizons: List[int]) -> pd.DataFrame:
        """
        Group by decile and horizon; compute metrics.
        
        Returns
        -------
        metrics_df : pd.DataFrame
            MultiIndex (decile, horizon) × metrics columns.
        """
        metrics = []
        for h in horizons:
            fwd = f"fwd_{h}d"
            grp = self.df.dropna(subset=['decile', fwd]).groupby('decile')[fwd]
            metrics.append(
                pd.DataFrame({
                    'horizon': h,
                    'mean': grp.mean(),
                    'median': grp.median(),
                    'std': grp.std(),
                    'hit_rate': grp.apply(lambda x: np.mean(x > 0)),
                    'sharpe': grp.mean() / grp.std(),
                    'VaR_5pct': grp.quantile(0.05),
                })
            )
        metrics_df = pd.concat(metrics).reset_index().set_index(['decile','horizon'])
        logger.info("Aggregated metrics shape: %s", metrics_df.shape)
        return metrics_df

    def plot_mean_by_decile(self, metrics_df: pd.DataFrame, horizon: int) -> None:
        """
        Bar plot of mean ± std for one horizon.
        """
        df_h = metrics_df.xs(horizon, level='horizon')
        plt.figure(figsize=(8, 4))
        plt.bar(df_h.index, df_h['mean'], yerr=df_h['std'], alpha=0.7)
        plt.xlabel('Decile of ' + self.x_col)
        plt.ylabel(f'Mean {self.y_col} return over {horizon}d')
        plt.title(f'{self.x_col} Deciles → {self.y_col} Forward Return')
        plt.show()

    def run(self, horizons: List[int]) -> Dict[str, pd.DataFrame]:
        """
        Full pipeline: assign deciles, compute forward, aggregate.
        
        Returns
        -------
        dict with keys:
            'metrics': metrics DataFrame,
            'data': cleaned working DataFrame
        """
        self.assign_deciles()
        self.compute_forward_returns(horizons)
        metrics = self.aggregate_metrics(horizons)
        return {'metrics': metrics, 'data': self.df}


# ─── Example Usage ─────────────────────────────────────────────────────────────
# df = pd.read_csv('my_data.csv', parse_dates=['date'], index_col='date')
# analysis = DecileForwardAnalysis(df, x_col='convenience_yield', y_col='term_premium')
# result = analysis.run(horizons=[1, 5, 20])
# print(result['metrics'])
# analysis.plot_mean_by_decile(result['metrics'], horizon=20)



import pandas as pd
from typing import Union

def rolling_weekly_average(
    data: Union[pd.Series, pd.DataFrame],
    window: Union[int, str] = '7D',
    min_periods: int = 1,
    forward: bool = False
) -> Union[pd.Series, pd.DataFrame]:
    """
    Compute rolling weekly average over a Series or DataFrame.

    Parameters
    ----------
    data : pd.Series or pd.DataFrame
        Time‑indexed data to roll over.
    window : int or str, default '7D'
        - If int, number of periods (rows) in the window.
        - If str, a pandas offset alias (e.g. '7D' for 7 calendar days,
          '1W' for 1 week, etc.).
    min_periods : int, default 1
        Minimum number of observations in window required to have a value.
    forward : bool, default False
        If False, compute backward‑looking (t‑window → t) average.
        If True, compute forward‑looking (t → t+window) average.

    Returns
    -------
    pd.Series or pd.DataFrame
        The same shape as `data`, with rolling averages.
    """
    if not isinstance(data, (pd.Series, pd.DataFrame)):
        raise TypeError("`data` must be a pandas Series or DataFrame")

    # Backward‑looking is just pandas.rolling().mean()
    if not forward:
        return data.rolling(window=window, min_periods=min_periods).mean()

    # Forward‑looking: reverse the index order, roll, then reverse back
    reversed_data = data.iloc[::-1]
    reversed_avg  = reversed_data.rolling(window=window, min_periods=min_periods).mean()
    return reversed_avg.iloc[::-1]



from sklearn.pipeline import Pipeline
import pandas as pd

# … your imports, definitions of fe_pipeline, model, etc.

# 1. Split your raw data as usual:
X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=…, random_state=…)

# 2. CONCATENATE train+test for feature‑engineering
X_combined = pd.concat([X_tr, X_te], axis=0)

# 3. FIT & TRANSFORM the combined set
#    – fit on all the data (so e.g. any encoders, scalers, imputers see the full range),
#    – then get a DataFrame back with proper indices & column names:
fe_pipeline.fit(X_combined)
X_combined_fe = fe_pipeline.transform(X_combined)

# if your pipeline returns a numpy array, wrap it back into a DataFrame:
try:
    feat_names = fe_pipeline.get_feature_names_out()
except:
    # fallback: if no get_feature_names_out, just reuse original names
    feat_names = X_combined.columns
X_combined_fe = pd.DataFrame(
    X_combined_fe,
    index=X_combined.index,
    columns=feat_names
)

# 4. SPLIT back into train & test
#    – use .loc with the original indices so that everything stays aligned
X_tr_fe = X_combined_fe.loc[X_tr.index]
X_te_fe = X_combined_fe.loc[X_te.index]

# 5. ALIGN your y’s (just to be safe if you dropped or reordered)
y_tr_aligned = y_tr.loc[X_tr_fe.index]
y_te_aligned = y_te.loc[X_te_fe.index]

# Now you can pass X_tr_fe, y_tr_aligned into your model.fit(),
# and X_te_fe, y_te_aligned into model.evaluate()/predict() as before.



from __future__ import annotations
import argparse, logging, os, warnings
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.decomposition import PCA
from sklearn.cross_decomposition import PLSRegression
from sklearn.linear_model import (
    LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge
)
from sklearn.model_selection import GridSearchCV, TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ---------------------------------------------------------------------------
# GLOBAL SELECTION + FINAL FIT + SUMMARY + ROLLING INFERENCE
# ---------------------------------------------------------------------------
def select_and_finalize(
    df: pd.DataFrame,
    target_col: str,
    metrics_df: pd.DataFrame,
    modes: List[str],
    train_periods: int,
    test_periods: int,
    window_type: str
):
    # Aggregate SSE over OOS to pick best config
    md = metrics_df.copy()
    md['OOS_SSE'] = md['OOS_RMSE']**2 * md['OOS_n']
    agg = md.groupby(['Mode','Model','Lags','Delta','Window']).agg(
        OOS_SSE=('OOS_SSE','sum'), OOS_n=('OOS_n','sum')
    )
    agg['Agg_RMSE'] = np.sqrt(agg['OOS_SSE']/agg['OOS_n'])
    best_cfg = agg['Agg_RMSE'].idxmin()
    logging.info("Best config: %s -> RMSE %.6f", best_cfg, agg.loc[best_cfg,'Agg_RMSE'])

    # Final full-sample training
    X_full = df.drop(columns=[target_col])
    y_full = df[target_col]
    feat_pipe = build_feature_pipeline(best_cfg[0], best_cfg[2], best_cfg[3], list(X_full.columns))
    X_fe_full = pd.DataFrame(feat_pipe.fit_transform(X_full), index=X_full.index).dropna()
    y_fe_full = y_full.reindex(X_fe_full.index)
    est, grid = LINEAR_MODELS[best_cfg[1]]
    if grid:
        cv = TimeSeriesSplit(n_splits=min(5, len(X_fe_full)//2))
        search = GridSearchCV(est, grid, cv=cv, scoring='neg_root_mean_squared_error', n_jobs=-1)
        search.fit(X_fe_full, y_fe_full)
        final_model = search.best_estimator_
    else:
        final_model = est.fit(X_fe_full, y_fe_full)

    # Save full-model info
    params = final_model.get_params()
    coefs = getattr(final_model, 'coef_', None)
    intercept = getattr(final_model, 'intercept_', None)
    with open('final_model_info.txt','w') as f:
        f.write(f"Config: {best_cfg}\nParams: {params}\nCoefficients: {coefs}\nIntercept: {intercept}\n")
    logging.info("Full-model information saved.")

    # Rolling-inference summary using statsmodels OLS on each window
    rolling_recs = []
    n = len(df)
    combos = [best_cfg]
    mode, model_name, use_lags, use_delta, wtype = best_cfg
    for start in range(train_periods, n - test_periods + 1, test_periods):
        # Define window indices
        if window_type == 'expanding':
            idx_tr = slice(0, start)
        else:
            idx_tr = slice(start - train_periods, start)
        idx_te = slice(start, start + test_periods)
        train = df.iloc[idx_tr]
        test = df.iloc[idx_te]
        X_tr = train.drop(columns=[target_col]); y_tr = train[target_col]
        X_te = test.drop(columns=[target_col]); y_te = test[target_col]
        # Features
        pipe = build_feature_pipeline(mode, use_lags, use_delta, list(X_tr.columns))
        X_tr_fe = pd.DataFrame(pipe.fit_transform(X_tr), index=X_tr.index).dropna()
        y_tr_al = y_tr.reindex(X_tr_fe.index)
        X_te_fe = pd.DataFrame(pipe.transform(X_te), index=X_te.index).dropna()
        y_te_al = y_te.reindex(X_te_fe.index)
        if X_tr_fe.empty or X_te_fe.empty:
            continue
        # Fit OLS for inference
        X_sm = sm.add_constant(X_tr_fe)
        ols = sm.OLS(y_tr_al, X_sm).fit()
        coef = ols.params.to_dict()
        pvals = ols.pvalues.to_dict()
        conf = {k: tuple(v) for k,v in ols.conf_int().iterrows()}
        # Predict next point: one-step ahead mean
        pred = final_model.predict(X_te_fe)[0]
        # Metrics for this window
        m_in = compute_metrics(y_tr_al.values, final_model.predict(X_tr_fe))
        m_oos = compute_metrics(y_te_al.values, final_model.predict(X_te_fe))
        rec = {
            'TrainEnd': df.index[start],
            'Coef': coef, 'PValues': pvals, 'ConfInt': conf,
            'IN_R2': m_in['R2'], 'OOS_R2': m_oos['R2'],
            'IN_RMSE': m_in['RMSE'], 'OOS_RMSE': m_oos['RMSE'],
            'Predicted': pred, 'Actual': y_te_al.iloc[0]
        }
        rolling_recs.append(rec)
    rolling_df = pd.DataFrame(rolling_recs)
    rolling_df.to_json('rolling_inference.json', orient='records', date_format='iso')
    logging.info("Rolling inference details saved.")

    # Plot full-sample actual vs predicted
    preds_full = final_model.predict(X_fe_full)
    plt.figure(figsize=(10,6))
    plt.plot(y_fe_full.index, y_fe_full, label='Actual')
    plt.plot(y_fe_full.index, preds_full, label='Predicted')
    plt.title('Full-sample Actual vs Predicted')
    plt.legend(); plt.tight_layout(); plt.savefig('full_actual_vs_pred.png')
    logging.info("Full-sample plot saved.")

    # Plot rolling one-step-ahead predictions
    dates = rolling_df['TrainEnd'] + pd.to_timedelta(test_periods, unit='D')
    plt.figure(figsize=(10,6))
    plt.plot(dates, rolling_df['Actual'], 'o-', label='Actual t+1')
    plt.plot(dates, rolling_df['Predicted'], 'x--', label='Predicted t+1')
    plt.title('Rolling One-Step-Ahead Predictions')
    plt.legend(); plt.tight_layout(); plt.savefig('rolling_preds.png')
    logging.info("Rolling predictions plot saved.")

# ---------------------------------------------------------------------------
# ENTRYPOINT
# ---------------------------------------------------------------------------
def main():
    parser = argparse.ArgumentParser(
        description='State-of-the-art linear forecasting with walk-forward evaluation'
    )
    parser.add_argument('--x', required=True, help='Path to features file')
    parser.add_argument('--y', required=True, help='Path to target file')
    parser.add_argument('--target', default='Y', help='Target column name')
    parser.add_argument('--window', choices=['expanding','rolling'], default='expanding',
                        help='Window type for walk-forward')
    parser.add_argument('--train_periods', type=int, default=36,
                        help='Initial training window length in observations')
    parser.add_argument('--test_periods', type=int, default=12,
                        help='Test window length in observations')
    args = parser.parse_args()

    loader = DataLoader(Path(args.x), Path(args.y))
    df = loader.load_panel(target_col=args.target, shift_target=True)

    metrics_df = evaluate_all_combinations(
        df, args.target,
        modes=['raw','static_z','rolling_z'],
        train_periods=args.train_periods,
        test_periods=args.test_periods,
        window_type=args.window
    )
    metrics_df.to_csv('all_metrics.csv', index=False)
    logging.info("All metrics saved to all_metrics.csv")

    select_and_finalize(df, args.target, metrics_df)

if __name__ == '__main__':
    main()




import numpy as np
import matplotlib.pyplot as plt

def plot_horizontal_gauge(series, title='Convenience Factor Gauge'):
    """
    Draws a horizontal gauge:
    - Red zone: below μ - σ
    - White zone: between μ - σ and μ + σ
    - Green zone: above μ + σ
    Pointer marks the most recent value.
    """
    # Prepare data
    data = series.dropna()
    current = data.iloc[-1]
    mu = data.mean()
    sigma = data.std(ddof=0)
    vmin, vmax = data.min(), data.max()
    low, high = mu - sigma, mu + sigma

    # Figure setup
    fig, ax = plt.subplots(figsize=(8, 2))
    ax.set_xlim(vmin, vmax)
    ax.set_ylim(0, 1)
    ax.axis('off')
    ax.set_title(title, pad=10, fontsize=14, fontweight='bold')

    # Colored zones
    ax.axvspan(vmin, low, ymin=0.25, ymax=0.75, color='red')
    ax.axvspan(low, high, ymin=0.25, ymax=0.75, color='white', edgecolor='black', lw=1)
    ax.axvspan(high, vmax, ymin=0.25, ymax=0.75, color='green')

    # Pointer arrow
    ax.annotate(
        '',
        xy=(current, 0.75), xytext=(current, 0.95),
        arrowprops=dict(arrowstyle='->', lw=2, color='black')
    )

    # Current value label
    ax.text(
        current, 1.02, f'{current:.2f}',
        ha='center', va='bottom', fontsize=12, fontweight='bold'
    )

    # Min/Max labels
    ax.text(vmin, 0.1, f'{vmin:.2f}', ha='left', va='center', fontsize=10)
    ax.text(vmax, 0.1, f'{vmax:.2f}', ha='right', va='center', fontsize=10)

    plt.tight_layout()
    plt.show()

# Usage example (replace `your_series` with your pandas Series):
# plot_horizontal_gauge(your_series, title='My Convenience Gauge')

import matplotlib.pyplot as plt
import numpy as np

# ← Replace this with your actual DataFrame:
# If your DataFrame is named `metrics_df`, use:
# df = metrics_df
# Or if you have a dict `result` containing it under 'metrics', use:
# df = result['metrics']
df = your_dataframe_here  

# Pivot the "mean" metric into a table: index=quintile, columns=horizon
pivot = (
    df['mean']                    # Select the mean column
      .unstack(level='horizon')  # Move horizon into columns
      .loc[:, [21, 63, 126]]     # Keep only the three horizons
)

# Plot
fig, ax = plt.subplots(figsize=(6, 4))
heat = ax.imshow(pivot.values, aspect='auto')

# Axis labels
ax.set_xticks(np.arange(pivot.shape[1]))
ax.set_xticklabels(pivot.columns)
ax.set_yticks(np.arange(pivot.shape[0]))
ax.set_yticklabels(pivot.index.astype(int))

# Annotate with numeric values
for i in range(pivot.shape[0]):
    for j in range(pivot.shape[1]):
        ax.text(
            j, i,
            f"{pivot.iloc[i, j]:.4f}",
            ha='center', va='center'
        )

ax.set_xlabel('Horizon (Days)')
ax.set_ylabel('Quintile')
ax.set_title('Mean by Quintile and Horizon')

# Colorbar
plt.colorbar(heat, ax=ax, fraction=0.046, pad=0.04)

plt.tight_layout()
plt.show()
