import argparse
import logging
from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score, TimeSeriesSplit
from sklearn.metrics import mean_squared_error, r2_score

# ─────────────────────────────────────────
# Logging & seed
# ─────────────────────────────────────────
SEED = 42
np.random.seed(SEED)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)8s | %(message)s",
    handlers=[logging.StreamHandler()]
)

# ─────────────────────────────────────────
# Data loader
# ─────────────────────────────────────────
class DataLoader:
    def __init__(self, x_path: Path, y_path: Path):
        # load X and Y
        if x_path.suffix.lower() in ['.parquet', '.pq']:
            self.x = pd.read_parquet(x_path)
        else:
            self.x = pd.read_csv(x_path, index_col=0, parse_dates=True)
        if y_path.suffix.lower() in ['.parquet', '.pq']:
            self.y = pd.read_parquet(y_path)
        else:
            self.y = pd.read_csv(y_path, index_col=0, parse_dates=True)

        # align dates and forward-fill any missing
        df = self.x.join(self.y, how='inner').sort_index().ffill()
        self.data = df.dropna()
        logging.info(f"Loaded and aligned {len(self.data)} obs × {self.x.shape[1]} features.")

    def split(self, holdout_years: int = 2):
        # last `holdout_years` * 12 months as test
        split_i = -12 * holdout_years
        train = self.data.iloc[:split_i]
        test  = self.data.iloc[split_i:]
        return train.drop(columns=[self.data.columns[-1]]), train.iloc[:, -1], \
               test.drop(columns=[self.data.columns[-1]]), test.iloc[:, -1]

# ─────────────────────────────────────────
# Transformers
# ─────────────────────────────────────────
class Lagger(TransformerMixin, BaseEstimator):
    def __init__(self, lags=3): self.lags = lags
    def fit(self, X, y=None): return self
    def transform(self, X):
        df = pd.DataFrame(
            {f"{col}_lag{lag}": X[col].shift(lag)
             for col in X.columns for lag in range(1, self.lags+1)},
            index=X.index)
        return df

class RollingZ(TransformerMixin, BaseEstimator):
    def __init__(self, window=36): self.window = window
    def fit(self, X, y=None): return self
    def transform(self, X):
        mu = X.rolling(window=self.window, min_periods=self.window//2).mean()
        sd = X.rolling(window=self.window, min_periods=self.window//2).std(ddof=0)
        return (X - mu) / sd

class Delta(TransformerMixin, BaseEstimator):
    def fit(self, X, y=None): return self
    def transform(self, X): return X.diff()

# ─────────────────────────────────────────
# Feature pipelines
# ─────────────────────────────────────────
def make_fe_pipeline(mode: str, raw_cols: list) -> ColumnTransformer:
    """
    Returns a ColumnTransformer that generates features according to `mode`:
       raw, static_z, rz, rz_delta, rz_lag, rz_lag_delta
    """
    transformers = []
    if mode == 'raw':
        # pass-through
        return ColumnTransformer([('raw', 'passthrough', raw_cols)], remainder='drop')
    # static z-score
    if mode == 'static_z':
        return ColumnTransformer([('std', StandardScaler(), raw_cols)], remainder='drop')

    # dynamic
    if 'rz' in mode:
        transformers.append(('rz', RollingZ(window=36), raw_cols))
    if 'lag' in mode:
        transformers.append(('lag', Lagger(lags=3), raw_cols))
    if 'delta' in mode:
        transformers.append(('d1', Delta(), raw_cols))
    return ColumnTransformer(transformers, remainder='drop')

# ─────────────────────────────────────────
# Evaluate
# ─────────────────────────────────────────
def evaluate_modes(X: pd.DataFrame,
                   y: pd.Series,
                   modes: list[str],
                   folds: int) -> pd.DataFrame:
    tscv = TimeSeriesSplit(n_splits=folds)
    results = []
    for mode in modes:
        logging.info(f"Evaluating feature mode: {mode}")
        # extract features
        fe = make_fe_pipeline(mode, X.columns.tolist())
        X_feat = fe.fit_transform(X)
        # wrap into DataFrame for alignment
        X_feat = pd.DataFrame(X_feat, index=X.index)
        # drop rows with any NaN (lags/rolling)
        X_feat = X_feat.dropna()
        # align target
        y_aligned = y.loc[X_feat.index]

        # simple model pipeline: scale + OLS
        pipe = Pipeline([
            ('scale', StandardScaler()),
            ('ols',   LinearRegression())
        ])

        # CV
        neg_rmse = cross_val_score(pipe, X_feat, y_aligned,
                                   cv=tscv,
                                   scoring='neg_root_mean_squared_error',
                                   n_jobs=-1)
        r2 = cross_val_score(pipe, X_feat, y_aligned,
                              cv=tscv,
                              scoring='r2',
                              n_jobs=-1)
        results.append({
            'mode': mode,
            'mean_rmse': -np.mean(neg_rmse),
            'std_rmse':  np.std( neg_rmse),
            'mean_r2':    np.mean(r2)
        })
    return pd.DataFrame(results)

# ─────────────────────────────────────────
# Main
# ─────────────────────────────────────────
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--x',      type=Path, required=True)
    parser.add_argument('--y',      type=Path, required=True)
    parser.add_argument('--holdout',type=int, default=2)
    parser.add_argument('--folds',  type=int, default=8)
    args = parser.parse_args()

    # load and split
    loader = DataLoader(args.x, args.y)
    Xtr, ytr, Xte, yte = loader.split(args.holdout)

    # evaluate six modes
    modes = ['raw', 'static_z', 'rz', 'rz_delta', 'rz_lag', 'rz_lag_delta']
    df_res = evaluate_modes(Xtr, ytr, modes, args.folds)
    print(df_res)

    # pick best
    best_mode = df_res.sort_values('mean_rmse').iloc[0]['mode']
    logging.info(f"Best feature mode: {best_mode}")

    # final fit + holdout
    fe = make_fe_pipeline(best_mode, Xtr.columns.tolist())
    X_tr_feat = fe.fit_transform(Xtr)
    X_tr_feat = pd.DataFrame(X_tr_feat, index=Xtr.index).dropna()
    y_tr_feat = ytr.loc[X_tr_feat.index]

    model = Pipeline([
        ('scale', StandardScaler()),
        ('ols',   LinearRegression())
    ])
    model.fit(X_tr_feat, y_tr_feat)

    # test
    X_te_feat = pd.DataFrame(fe.transform(Xte), index=Xte.index).dropna()
    y_te_feat = yte.loc[X_te_feat.index]
    y_pred = model.predict(X_te_feat)
    print("Holdout RMSE:", mean_squared_error(y_te_feat, y_pred, squared=False))
    print("Holdout R2:  ", r2_score(y_te_feat, y_pred))

if __name__ == '__main__':
    main()
